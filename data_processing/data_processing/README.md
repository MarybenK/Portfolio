# Data Processing & Regression Models

This directory contains practical machine learning workflows focused on regression, feature preparation, 
and model evaluation.

## housing_price_regression.ipynb
This project builds a regression model using the California Housing Dataset.

### Key Steps Covered
- Loading and inspecting raw data
- Data cleaning and preprocessing
- Feature/target selection
- Splitting into training and test sets
- Building a Linear Regression model
- Evaluating performance using RMSE and R²
- Visualizing predicted vs. actual housing prices

## pyspark_cluster_setup_and_analysis.ipynb
This notebook demonstrates a full PySpark workflow, including:

### ▶ Environment Setup
- Installing PySpark
- Configuring dependencies
- Initializing a Spark cluster

### ▶ Cluster Verification
- Checking session creation
- Confirming cluster runtime
- Viewing Spark configuration

### ▶ Data Processing
- Creating Spark DataFrames
- Running transformations
- Applying filters, selects, and aggregations
- Inspecting schema and execution plans

### ▶ Practical Skills Demonstrated
- Distributed computation fundamentals
- Real-world Spark workflow structure
- Scalable data engineering operations



## sql_database_analysis.ipynb
This notebook demonstrates a complete SQL-based data analysis workflow.

### Key tasks:
- Connecting to a relational database
- Exploring database tables and schema
- Running SQL queries (SELECT, JOIN, GROUP BY, WHERE)
- Performing aggregations and filtering
- Extracting insights from structured data
- Preparing cleaned datasets for further analysis

This notebook represents a typical real-world data engineering or database analytics task.

### Key topics covered:
- Installing and configuring PySpark
- Creating and verifying a Spark session
- Inspecting Spark configuration and cluster details
- Creating Spark DataFrames
- Running transformations (select, filter, groupBy, agg)
- Performing actions (show, count, collect)
- Understanding lazy execution and distributed processing
